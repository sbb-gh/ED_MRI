{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODOS\n",
    "# Add Rician objective function for LSQ fitting.\n",
    "# rewrite for experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "(c) Stefano B. Blumberg and Paddy J. Slator, do not redistribute or modify\n",
    "\n",
    "Code to replicate the ADC experiment (alongside matlab code - maybe translate to python?) <Add paper link>\n",
    "\n",
    "Overview for cells:\n",
    "    - Choose data size splits 2\n",
    "    - Generate data examples 3-A/B/C\n",
    "    - Data format for JOFSTO 4\n",
    "    - Option to pass data directly, or save to disk and load 5-A/B\n",
    "    - JOFSTO hyperparameters 6,7,8\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## (1)\n",
    "# Import modules, see requirements.txt for jofsto requirements, set global seed\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "import os, yaml \n",
    "from jofsto_code.jofsto_main import return_argparser, run\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(0)  # Random seed for entire script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Directories and filenames to save data (Replace with location of JOFSTO code - possible to get this automatically?)\n",
    "basedir = '/Users/paddyslator/python/ED_MRI/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## (2)\n",
    "# Data split sizes\n",
    "\n",
    "n_train = 100000  # No. training voxels, reduce for faster training speed\n",
    "n_val = n_train // 10  # No. validations set voxels\n",
    "n_test = n_train // 10  # No. test set voxels\n",
    "\n",
    "n_samples = n_train + n_val + n_test #total number of samples to simulate\n",
    "\n",
    "#choose the size of the super-design\n",
    "C_bar = 192\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define some models and generate the data\n",
    "\n",
    "model_name = 't1inv'\n",
    "\n",
    "if model_name == 'adc':\n",
    "    #model equation for simulation\n",
    "    def model(D,bvals):\n",
    "        signals = np.exp(-bvals*D)\n",
    "        return signals\n",
    "    \n",
    "    #min/max parameter values\n",
    "    minD = 0.1\n",
    "    maxD = 3\n",
    "    \n",
    "    #simulate parameter values\n",
    "    parameters = np.random.uniform(low=minD,high=maxD,size=(n_samples,1))\n",
    "\n",
    "    #Generate data using the model\n",
    "    \n",
    "    #make the super design\n",
    "    maxb = 5\n",
    "    minb = 0\n",
    "    acq_params_super = np.linspace(minb,maxb,C_bar)\n",
    "    \n",
    "    #generate the data    \n",
    "    raw_signals = np.zeros((n_samples,C_bar),dtype = np.float32)\n",
    "    for i in range(0,n_samples):\n",
    "        raw_signals[i,:] = model(parameters[i],acq_params_super)\n",
    "    \n",
    "    \n",
    "elif model_name == 't1inv':\n",
    "    def model(T1,ti,tr):\n",
    "        signals = abs(1 - (2*np.exp(-ti/T1)) + np.exp(-tr/T1))\n",
    "        return signals\n",
    "    \n",
    "    #min/max parameter values\n",
    "    minT1 = 0.1\n",
    "    maxT1 = 7\n",
    "    #simulate parameter values\n",
    "    parameters = np.random.uniform(low=minT1,high=maxT1,size=(n_samples,1))\n",
    "    \n",
    "    #generate data using an T1 inversion recovery model \n",
    "    \n",
    "    #make the super design\n",
    "    tr = 7 #repetition time\n",
    "    maxti = tr\n",
    "    minti = 0.1\n",
    "    acq_params_super = np.linspace(minti,maxti,C_bar)\n",
    "    \n",
    "    #generate the data\n",
    "    raw_signals = np.zeros((n_samples,C_bar),dtype = np.float32)\n",
    "    for i in range(0,n_samples):\n",
    "        raw_signals[i,:] = model(parameters[i],acq_params_super,tr)\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## (3-A)\n",
    "# Create dummy, randomly generated (positive) data\n",
    "\n",
    "# C_bar = 220\n",
    "# M = 12  # Number of input measurements \\bar{C}, Target regressors\n",
    "# rand = np.random.lognormal  # Random genenerates positive\n",
    "# train_inp, train_tar = rand(size=(n_train, C_bar)), rand(size=(n_train, M))\n",
    "# val_inp, val_tar = rand(size=(n_val, C_bar)), rand(size=(n_val, M))\n",
    "# test_inp, test_tar = rand(size=(n_test, C_bar)), rand(size=(n_test, M))\n",
    "\n",
    "\n",
    "# #########\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add noise to the data\n",
    "def add_noise(data, scale=0.05):\n",
    "    data_real = data + np.random.normal(scale=scale, size=np.shape(data))\n",
    "    data_imag = np.random.normal(scale=scale, size=np.shape(data))\n",
    "    data_noisy = np.sqrt(data_real**2 + data_imag**2)\n",
    "\n",
    "    return data_noisy\n",
    "\n",
    "\n",
    "SNR = 20\n",
    "signals = add_noise(raw_signals,1/SNR)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## (4)\n",
    "# Load data into JOFSTO format\n",
    "\n",
    "# Data in JOFSTO format, \\bar{C} measurements, M target regresors\n",
    "data = dict(\n",
    "    train=signals[0:n_train,:],  # Shape n_train x \\bar{C}\n",
    "    train_tar=parameters[0:n_train,:],  # Shape n_train x M\n",
    "    val=signals[n_train:(n_train + n_val),:],  # Shape n_val x \\bar{C}\n",
    "    val_tar=parameters[n_train:(n_train + n_val),:],  # Shape n_val x M\n",
    "    test=signals[(n_train + n_val):(n_train + n_val + n_test),:],  # Shape n_test x \\bar{C}\n",
    "    test_tar=parameters[(n_train + n_val):(n_train + n_val + n_test),:],  # Shape n_test x M\n",
    ")\n",
    "\n",
    "#with open(os.path.dirname(__file__) + \"/base.yaml\", \"r\") as f:\n",
    "#with open(\"/home/blumberg/Bureau/z_Automated_Measurement/Code/base.yaml\", \"r\") as f:\n",
    "with open(os.path.join(basedir, \"base.yaml\"), \"r\") as f:\n",
    "    jofsto_args =  yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## (5-A)\n",
    "# Option to save data to disk, and JOFSTO load\n",
    "\n",
    "# Check whether a path for this model exists or not - if not create it\n",
    "data_dir = os.path.join(basedir,'output',model_name + '_simulations')\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "    \n",
    "\n",
    "proj_params =  '_simulations_' + 'n_train_' + str(n_train) + '_SNR_' + str(SNR)\n",
    "    \n",
    "data_fil = os.path.join(data_dir, model_name + proj_params +  '.npy')\n",
    "#data_fil = \"/home/blumberg/Bureau/z_Automated_Measurement/Output/paddy/adc_simulations.npy\"\n",
    "#data_fil = \"/Users/paddyslator/python/ED_MRI/adc_simulations.npy\"  # Add path to save file\n",
    "np.save(data_fil, data)\n",
    "print(\"Saving data as\", data_fil)\n",
    "pass_data = None\n",
    "\n",
    "jofsto_args[\"--data_fil\"] = data_fil\n",
    "\n",
    "\n",
    "########## (5-B)\n",
    "# Option to pass data to JOFSTO directly\n",
    "\n",
    "pass_data = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## (6)\n",
    "# Simplest version of JOFSTO, modifying the most important hyperparameters\n",
    "\n",
    "\n",
    "# Decreasing feature subsets sizes for JOFSTO to consider\n",
    "jofsto_args[\"jofsto_train_eval\"][\"C_i_values\"] = [C_bar, C_bar // 2, C_bar // 4, C_bar // 8, C_bar // 16]\n",
    "\n",
    "# Feature subset sizess for JOFSTO evaluated on test data\n",
    "jofsto_args['jofsto_train_eval'][\"C_i_eval\"] = [C_bar // 2, C_bar // 4, C_bar // 8, C_bar // 16]\n",
    "\n",
    "# Scoring net C_bar -> num_units_score[0] -> num_units_score[1] ... -> C_bar units\n",
    "jofsto_args['network'][\"num_units_score\"] = [1000, 1000]\n",
    "\n",
    "# Task net C_bar -> num_units_task[0] -> num_units_task[1] ... -> M units\n",
    "jofsto_args['network'][\"num_units_task\"] = [1000, 1000]\n",
    "\n",
    "jofsto_args['output'][\"out_base\"] =  data_dir  #\"/Users/paddyslator/python/ED_MRI/test1\" #\"/home/blumberg/Bureau/z_Automated_Measurement/Output/paddy\"\n",
    "jofsto_args['output'][\"proj_name\"] = model_name + proj_params\n",
    "jofsto_args['output'][\"run_name\"] = \"test\"\n",
    "\n",
    "jofsto_args['other_options']['save_output'] = True\n",
    "\n",
    "#jofsto_args[\"total_epochs\"] = 1000\n",
    "\n",
    "JOFSTO_output_small = run(args=jofsto_args, pass_data=pass_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the FULL JOFSTO output\n",
    "JOFSTO_output = np.load(os.path.join(basedir,jofsto_args['output'][\"out_base\"],jofsto_args['output'][\"proj_name\"],\"results\", jofsto_args['output'][\"run_name\"] + \"_all.npy\"), allow_pickle=True).item()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract some useful parameters fom the jofsto output\n",
    "#final subset index\n",
    "C_last = JOFSTO_output['args']['jofsto_train_eval']['C_i_eval'][-1]\n",
    "#chosen acquisition parameters\n",
    "acq_params_jofsto = acq_params_super[JOFSTO_output[C_last]['measurements']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "#define CRLB functions \n",
    "\n",
    "if model_name == 'adc':\n",
    "    def f_crlb(b,params,sigma):\n",
    "        #params[0] is S0\n",
    "        #params[1] is ADC \n",
    "        #params = np.zeros(2)\n",
    "        #params[0] = 1\n",
    "        #params[1] = 1\n",
    "        #sigma = 0.05  \n",
    "        \n",
    "        #need 2 b-values - so assume there is always a b=0 (CRLB with 2 b-values always chooses a b=0 anyway)\n",
    "        b=np.insert(b,0,0)\n",
    "                        \n",
    "        dy = np.zeros((len(b),2))\n",
    "        dy[:,0] = np.exp(-b * params[1])\n",
    "        dy[:,1] = -b*params[0]*np.exp(-b*params[1])\n",
    "       \n",
    "        fisher = (np.matmul(dy.T,dy))/sigma**2\n",
    "\n",
    "        invfisher = np.linalg.inv(fisher)\n",
    "        #second diagonal element is the lower bound on the variance of the ADC\n",
    "        f = invfisher[1,1]\n",
    "\n",
    "        return f\n",
    "elif model_name == 't1inv':\n",
    "    def f_crlb(ti,params,tr,sigma):\n",
    "        #params[0] is S0\n",
    "        #params[1] is T1  \n",
    "        #convert to R1\n",
    "        params[1] = 1/params[1]\n",
    "        #tr = 7\n",
    "        #sigma = 1 \n",
    "\n",
    "        dy = np.zeros((len(ti),2))\n",
    "        dy[:,0] = (1 - 2*np.exp(-ti * params[1]) + np.exp(-tr*params[1])) \n",
    "        dy[:,1] = params[0]*(2*ti*np.exp(-ti*params[1]) -tr*np.exp(-tr*params[1]))\n",
    "        \n",
    "        fisher = (np.matmul(dy.T,dy))/sigma**2\n",
    "\n",
    "        invfisher = np.linalg.inv(fisher)\n",
    "        #second diagonal element is the lower bound on the variance of R1\n",
    "        f = invfisher[1,1]\n",
    "\n",
    "        return f\n",
    "\n",
    "\n",
    "#calculate CRLB optimal acquisition parameter (e.g. b-value, TI) for a range of model parameters (e.g. ADC, T1)\n",
    "\n",
    "#match number of model parameters in the range to the number of measurements in the final JOFSTO output\n",
    "\n",
    "\n",
    "#Calculate the range of parameters\n",
    "if model_name == 'adc': \n",
    "    params = np.linspace(0,maxD,C_last)[1:] #one less parameter for ADC as CRLB assumes a b=0\n",
    "elif model_name == 't1inv':\n",
    "    params = np.linspace(0,maxT1,C_last+1)[1:] \n",
    "    \n",
    "#initialise array of CRLB-optimsed acquisition parameters (e.g. b-values, TI)\n",
    "acq_params_crlb = np.zeros(C_last)\n",
    "\n",
    "#these don't affect the optimisation so can be fixed\n",
    "S0 = 1\n",
    "sigma = 1/SNR\n",
    "\n",
    "for i in range(0,len(params)):\n",
    "    if model_name == 'adc':\n",
    "        fixed_args = (np.array((S0,params[i])),sigma)\n",
    "        bnds=((minb,maxb),)\n",
    "        init = 1/params[i]\n",
    "#        init = np.array((1/params[i],2/params[i]))\n",
    "    elif model_name == 't1inv':\n",
    "        fixed_args = (np.array((S0,params[i])), tr, sigma)\n",
    "        bnds=((minti,maxti),)\n",
    "        init = params[i]\n",
    "        \n",
    "    acq_params_crlb[i] = minimize(f_crlb, init, args=fixed_args, method='Nelder-Mead',bounds=bnds).x\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #calculate robust CRLB by summing over many possible D/T1's\n",
    "# #as in McHugh et al. MRM 2018 doi: 10.1002/mrm.27551\n",
    "\n",
    "# #take the first 100 parameters (as in McHugh)\n",
    "# parameters_robust = parameters[0:100]\n",
    "\n",
    "# def f_crlb_robust(b,S0,parameters_robust,sigma):\n",
    "#     for param in parameters_robust:\n",
    "#         f_summand = f_crlb(b,np.array((S0,param),dtype=object),sigma)\n",
    "        \n",
    "#     return np.sum(np.log(f_summand))\n",
    "\n",
    "\n",
    "# if model_name == 'adc':\n",
    "#     fixed_args = (S0,parameters_robust,sigma)\n",
    "#     bnds=((minb,maxb),)\n",
    "#     init = 1/params[i]\n",
    "#     init = np.array((1/params[i],2*params[i],3*params[i]))\n",
    "# elif model_name == 't1inv':\n",
    "#     fixed_args = (S0,parameters_robust, tr, sigma)\n",
    "#     bnds=((minti,maxti),)\n",
    "#     init = params[i]\n",
    "        \n",
    "\n",
    "# acq_params_CRLB_robust = minimize(f_crlb_robust, np.linspace(minb,maxb,C_last), args=fixed_args, method='Nelder-Mead',bounds=bnds).x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the JOFSTO and CRLB acquisition parameters (e.g. b-values, TI,...)\n",
    "#all super-design acquisition parameters\n",
    "paramtest = params[5]\n",
    "\n",
    "if model_name == 'adc':\n",
    "    #all super-design b-values\n",
    "    plt.plot(acq_params_super,model(paramtest,acq_params_super),'k.',markersize=2)\n",
    "    #JOFSTO chosen b-values\n",
    "    C_last = JOFSTO_output['args']['jofsto_train_eval']['C_i_eval'][-1]\n",
    "    plt.plot(acq_params_jofsto, model(paramtest, acq_params_jofsto),'bs',fillstyle='none',markeredgewidth=2)\n",
    "    #CRLB chosen b-values\n",
    "    plt.plot(acq_params_crlb,model(paramtest,acq_params_crlb),'rs',fillstyle='none')\n",
    "    plt.legend(['super-design','JOFSTO','CRLB'],fontsize=14)\n",
    "    plt.xlabel('b-value ($\\mu$m$^2$ s$^{-1}$)',fontsize=14)\n",
    "elif model_name == 't1inv':\n",
    "    #all super-design b-values\n",
    "    plt.plot(acq_params_super,model(paramtest,acq_params_super,tr),'k.',markersize=2)\n",
    "    #JOFSTO chosen b-values\n",
    "    C_last = JOFSTO_output['args']['jofsto_train_eval']['C_i_eval'][-1]\n",
    "    plt.plot(acq_params_jofsto, model(paramtest,acq_params_jofsto,tr),'bs',fillstyle='none',markeredgewidth=2)\n",
    "    #CRLB chosen b-values\n",
    "    plt.plot(acq_params_crlb,model(paramtest,acq_params_crlb,tr),'r.',markeredgewidth=3)\n",
    "    plt.legend(['Super design','JOFSTO','CRLB'],fontsize=14)\n",
    "    plt.xlabel('Inversion time (s)',fontsize=14)\n",
    "\n",
    "\n",
    "plt.ylabel('Signal',fontsize=14)\n",
    "    \n",
    "#define location to save figures\n",
    "fig_dir = os.path.join(basedir,'figures')\n",
    "# Check whether a path for this model exists or not - if not create it\n",
    "if not os.path.exists(fig_dir):\n",
    "    os.makedirs(fig_dir)\n",
    "    \n",
    "#base filename for saving figures    \n",
    "fig_basename = model_name + '_simulations_n_train_' + str(n_train) + '_' + str(SNR)\n",
    "\n",
    "plt.savefig(os.path.join(fig_dir,fig_basename + '_acq_params.png'),dpi=300)\n",
    "plt.savefig(os.path.join(fig_dir,fig_basename + '_acq_params.eps'),dpi=300)\n",
    "plt.savefig(os.path.join(fig_dir,fig_basename + '_acq_params.pdf'),dpi=300)\n",
    "\n",
    "\n",
    "print('TO DO: move this to the plotting function and plot for all SNR. In text: \"we examine the chosen acquisition schemes for the simple models\"')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper functions for model fitting \n",
    "\n",
    "def rician_log_likelihood(signals,synth_signals,sigma):\n",
    "    sumsqsc = (signals**2 + synth_signals**2)/(2 * sigma**2)\n",
    "#    print(\"sumsqsc: \" + str(sumsqsc))\n",
    "    scp = synth_signals * signals / sigma**2  \n",
    "#    print(\"scp: \" + str(scp))   \n",
    "#    lb0 = np.log(np.i0(scp))\n",
    "    lb0 = log_i0(scp)\n",
    "#    print(\"lb0: \" + str(lb0))   \n",
    "    log_likelihoods = -2*np.log(sigma) - sumsqsc + np.log(synth_signals) + lb0\n",
    "#    print(\"log_likelihoods: \" + str(log_likelihoods))   \n",
    "\n",
    "\n",
    "    return np.sum(log_likelihoods)\n",
    "\n",
    "if model_name == 'adc':\n",
    "    def rician_objective_function(D,bvals,signals,sigma):\n",
    "        return -rician_log_likelihood(model(D,bvals),signals,sigma)\n",
    "\n",
    "    def gaussian_objective_function(D,bvals,signals):\n",
    "        return np.mean((signals - model(D,bvals))**2)\n",
    "elif model_name == 't1inv':\n",
    "    def rician_objective_function(T1,ti,tr,signals,sigma):\n",
    "        return -rician_log_likelihood(model(T1,ti,tr),signals,sigma)\n",
    "\n",
    "    def gaussian_objective_function(T1,ti,tr,signals):\n",
    "        return np.mean((signals - model(T1,ti,tr))**2)\n",
    "\n",
    "\n",
    "\n",
    "def log_i0(x):\n",
    "    exact = x < 700\n",
    "    approx = x >= 700\n",
    "   \n",
    "    lb0 = np.zeros(np.shape(x))\n",
    "    lb0[exact] = np.log(np.i0(x[exact]))\n",
    "    #This is a more standard approximation.  For large x, I_0(x) -> exp(x)/sqrt(2 pi x).\n",
    "    lb0[approx] = x[approx] - np.log(2*np.pi*x[approx])/2\n",
    "    \n",
    "    return lb0\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "#fit the model on the super-design acquisition, JOFSTO acquisition, CRLB acquisition\n",
    "\n",
    "#choose the noise level\n",
    "sigma_test = 1/SNR #set to the level of the training data simulations\n",
    "#sigma_test = 0.2 #set to something else\n",
    "\n",
    "\n",
    "#for the super design use the test data signals - but with different noise \n",
    "raw_signals_super = signals[(n_train + n_val):(n_train + n_val + n_test),:]\n",
    "signals_super = add_noise(raw_signals_super,sigma_test)\n",
    "\n",
    "#for jofsto use the reconstructed data\n",
    "signals_jofsto = signals[(n_train + n_val):(n_train + n_val + n_test),JOFSTO_output[C_last]['measurements']] \n",
    "\n",
    "\n",
    "#for CRLB simulate data for the CRLB acquisition - as don't have test data at these b-values\n",
    "signals_crlb = np.zeros((n_test,C_last))\n",
    "#use the ground truth parameters from the test dataset\n",
    "gt_parameters = data[\"test_tar\"][:,0]\n",
    "for i in range(0,n_test):\n",
    "    if model_name == 'adc':\n",
    "        signals_crlb[i,:] = add_noise(model(gt_parameters[i],acq_params_crlb),scale=sigma_test)\n",
    "    if model_name == 't1inv':\n",
    "        signals_crlb[i,:] = add_noise(model(gt_parameters[i],acq_params_crlb,tr),scale=sigma_test)\n",
    "\n",
    "    \n",
    "\n",
    "#choose starting parameter value for the fit - this should work fine for both models\n",
    "paramstart = 2\n",
    "\n",
    "fitted_parameters_crlb = np.zeros(n_test)\n",
    "fitted_parameters_super = np.zeros(n_test)\n",
    "fitted_parameters_jofsto = np.zeros(n_test)\n",
    "\n",
    "\n",
    "#fit the models to the data\n",
    "#Note that we pass the ground truth sigma to the fitting methods - but JOFSTO_NN never sees the ground truth sigma\n",
    "for i in range(0,n_test):\n",
    "    if model_name == 'adc':\n",
    "        fitted_parameters_crlb[i] = minimize(rician_objective_function, paramstart, args=(acq_params_crlb,signals_crlb[i,:],sigma_test),method='Nelder-Mead').x\n",
    "        fitted_parameters_super[i] = minimize(rician_objective_function, paramstart, args=(acq_params_super,signals_super[i,:],sigma_test),method='Nelder-Mead').x\n",
    "        fitted_parameters_jofsto[i] = minimize(rician_objective_function, paramstart, args=(acq_params_jofsto,signals_jofsto[i,:],sigma_test),method='Nelder-Mead').x\n",
    "    if model_name == 't1inv':\n",
    "        fitted_parameters_crlb[i] = minimize(rician_objective_function, paramstart, args=(acq_params_crlb,tr,signals_crlb[i,:],sigma_test),method='Nelder-Mead').x\n",
    "        fitted_parameters_super[i] = minimize(rician_objective_function, paramstart, args=(acq_params_super,tr,signals_super[i,:],sigma_test),method='Nelder-Mead').x\n",
    "        fitted_parameters_jofsto[i] = minimize(rician_objective_function, paramstart, args=(acq_params_jofsto,tr,signals_jofsto[i,:],sigma_test),method='Nelder-Mead').x\n",
    "        \n",
    "  \n",
    "\n",
    "    \n",
    "#extract the JOFSTO nn fit\n",
    "fitted_parameters_jofsto_nn = JOFSTO_output[jofsto_args[\"jofsto_train_eval\"][\"C_i_values\"][-1]][\"test_output\"][:,0]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the ground truth parameters, signals, and fitted parameters for plotting later (ground truth is saved as \"data\" above)\n",
    "\n",
    "#crlb test signals\n",
    "#np.save(os.path.splitext(data_fil)[0] + '_signals_crlb.npy', signals_crlb) \n",
    "np.save(os.path.join(data_dir, model_name + proj_params, 'signals_crlb.npy'), signals_crlb)\n",
    "\n",
    "#super design test signals - these are already saved as \"data\" dictionary above but also save here for neatness\n",
    "#np.save(os.path.splitext(data_fil)[0] + '_signals_super.npy', signals_super) \n",
    "np.save(os.path.join(data_dir, model_name + proj_params, 'signals_super.npy'), signals_super)\n",
    "\n",
    "#jofsto recon test signals - also saved in the jofsto output but also save separately for neatness\n",
    "#np.save(os.path.splitext(data_fil)[0] + '_signals_jofsto.npy', signals_jofsto) \n",
    "np.save(os.path.join(data_dir, model_name + proj_params, 'signals_jofsto.npy'), signals_jofsto)\n",
    "\n",
    "\n",
    "#save the lsq fits\n",
    "#np.save(os.path.splitext(data_fil)[0] + '_fit_crlb.npy', fitted_parameters_crlb) \n",
    "np.save(os.path.join(data_dir, model_name + proj_params, 'fit_crlb.npy'), fitted_parameters_crlb)\n",
    "\n",
    "#np.save(os.path.splitext(data_fil)[0] + '_fit_super.npy', fitted_parameters_super) \n",
    "np.save(os.path.join(data_dir, model_name + proj_params, 'fit_super.npy'), fitted_parameters_super)\n",
    "\n",
    "#np.save(os.path.splitext(data_fil)[0] + '_fit_jofsto_lsq.npy', fitted_parameters_jofsto) \n",
    "np.save(os.path.join(data_dir, model_name + proj_params, 'fit_jofsto_lsq.npy'), fitted_parameters_jofsto)\n",
    "\n",
    "\n",
    "#save the jofsto nn fits\n",
    "#np.save(os.path.splitext(data_fil)[0] + '_fit_jofsto_nn.npy', fitted_parameters_jofsto_nn) \n",
    "np.save(os.path.join(data_dir, model_name + proj_params, 'fit_jofsto_nn.npy'), fitted_parameters_jofsto_nn)\n",
    "\n",
    "\n",
    "#save the test dataset ground truth parameters\n",
    "#np.save(os.path.splitext(data_fil)[0] + '_parameters_gt.npy', gt_parameters) \n",
    "np.save(os.path.join(data_dir, model_name + proj_params, 'parameters_gt.npy'), gt_parameters)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "#super design full dataset signals - these are already saved as \"data\" dictionary above but also save here for neatness\n",
    "#np.save(os.path.splitext(data_fil)[0] + '_signals_super_full.npy', signals) \n",
    "np.save(os.path.join(data_dir, model_name + proj_params, 'signals_super_full.npy'), signals)\n",
    "\n",
    "\n",
    "#save the full dataset ground truth parameters \n",
    "#np.save(os.path.splitext(data_fil)[0] + '_parameters_gt_full.npy', parameters) \n",
    "np.save(os.path.join(data_dir, model_name + proj_params, 'parameters_gt_full.npy'), parameters)\n",
    "\n",
    "#save the super design acquisition parameters\n",
    "#np.save(os.path.splitext(data_fil)[0] + '_acq_params_super.npy', acq_params_super)\n",
    "np.save(os.path.join(data_dir, model_name + proj_params, 'acq_params_super.npy'), acq_params_super)\n",
    "\n",
    "#save the CRLB acquisition parameters\n",
    "#np.save(os.path.splitext(data_fil)[0] + '_acq_params_super.npy', acq_params_super)\n",
    "np.save(os.path.join(data_dir, model_name + proj_params, 'acq_params_crlb.npy'), acq_params_crlb)\n",
    "\n",
    "#save the JOFSTO acquisition parameters\n",
    "np.save(os.path.join(data_dir, model_name + proj_params, 'acq_params_jofsto.npy'), acq_params_jofsto)\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## (7)\n",
    "# Modify more JOFSTO hyperparameters, less important, may change results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "########## (8)\n",
    "# Deep learning training hyperparameters for inner loop"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "615b1a4c774898c50e50cbbdb62428ce29922c4c76c6af0df5092a4f94b8ccac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
