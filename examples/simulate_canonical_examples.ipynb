{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODOS\n",
    "# Add Rician objective function for LSQ fitting.\n",
    "# rewrite for experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "(c) Stefano B. Blumberg and Paddy J. Slator, do not redistribute or modify\n",
    "\n",
    "Code to replicate the ADC experiment (alongside matlab code - maybe translate to python?) <Add paper link>\n",
    "\n",
    "Overview for cells:\n",
    "    - Choose data size splits 2\n",
    "    - Generate data examples 3-A/B/C\n",
    "    - Data format for TADRED 4\n",
    "    - Option to pass data directly, or save to disk and load 5-A/B\n",
    "    - TADRED hyperparameters 6,7,8\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## (1)\n",
    "# Import modules, see requirements.txt for tadred requirements, set global seed\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from tadred import tadred_main, utils\n",
    "from pathlib import Path\n",
    "\n",
    "np.random.seed(0)  # Random seed for entire script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories and filenames to save data (Replace with location of TADRED code - possible to get this automatically?)\n",
    "# basedir = '/Users/paddyslator/python/ED_MRI/'\n",
    "basedir = \"/home/blumberg/Bureau/z_Automated_Measurement/Output/tst/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## (2)\n",
    "# Data split sizes\n",
    "\n",
    "n_train = 10**5  # No. training voxels, reduce for faster training speed\n",
    "n_val = n_train // 10  # No. validations set voxels\n",
    "n_test = n_train // 10  # No. test set voxels\n",
    "\n",
    "n_samples = n_train + n_val + n_test  # total number of samples to simulate\n",
    "\n",
    "# choose the size of the super-design\n",
    "Cbar = 192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some models and generate the data\n",
    "\n",
    "# model_name = 't1inv'\n",
    "model_name = \"adc\"\n",
    "\n",
    "if model_name == \"adc\":\n",
    "    # model equation for simulation\n",
    "    def model(D, bvals):\n",
    "        signals = np.exp(-bvals * D)\n",
    "        return signals\n",
    "\n",
    "    # min/max parameter values\n",
    "    minD = 0.1\n",
    "    maxD = 3\n",
    "\n",
    "    # simulate parameter values\n",
    "    parameters = np.random.uniform(low=minD, high=maxD, size=(n_samples, 1))\n",
    "\n",
    "    # Generate data using the model\n",
    "\n",
    "    # make the super design\n",
    "    maxb = 5\n",
    "    minb = 0\n",
    "    acq_params_super = np.linspace(minb, maxb, Cbar)\n",
    "\n",
    "    # generate the data\n",
    "    raw_signals = np.zeros((n_samples, Cbar), dtype=np.float32)\n",
    "    for i in range(0, n_samples):\n",
    "        raw_signals[i, :] = model(parameters[i], acq_params_super)\n",
    "\n",
    "\n",
    "elif model_name == \"t1inv\":\n",
    "\n",
    "    def model(T1, ti, tr):\n",
    "        signals = abs(1 - (2 * np.exp(-ti / T1)) + np.exp(-tr / T1))\n",
    "        return signals\n",
    "\n",
    "    # min/max parameter values\n",
    "    minT1 = 0.1\n",
    "    maxT1 = 7\n",
    "    # simulate parameter values\n",
    "    parameters = np.random.uniform(low=minT1, high=maxT1, size=(n_samples, 1))\n",
    "\n",
    "    # generate data using an T1 inversion recovery model\n",
    "\n",
    "    # make the super design\n",
    "    tr = 7  # repetition time\n",
    "    maxti = tr\n",
    "    minti = 0.1\n",
    "    acq_params_super = np.linspace(minti, maxti, Cbar)\n",
    "\n",
    "    # generate the data\n",
    "    raw_signals = np.zeros((n_samples, Cbar), dtype=np.float32)\n",
    "    for i in range(0, n_samples):\n",
    "        raw_signals[i, :] = model(parameters[i], acq_params_super, tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## (3-A)\n",
    "# Create dummy, randomly generated (positive) data\n",
    "\n",
    "# C_bar = 220\n",
    "# M = 12  # Number of input measurements \\bar{C}, Target regressors\n",
    "# rand = np.random.lognormal  # Random genenerates positive\n",
    "# train_inp, train_tar = rand(size=(n_train, C_bar)), rand(size=(n_train, M))\n",
    "# val_inp, val_tar = rand(size=(n_val, C_bar)), rand(size=(n_val, M))\n",
    "# test_inp, test_tar = rand(size=(n_test, C_bar)), rand(size=(n_test, M))\n",
    "\n",
    "\n",
    "# #########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add noise to the data\n",
    "def add_noise(data, scale=0.05):\n",
    "    data_real = data + np.random.normal(scale=scale, size=np.shape(data))\n",
    "    data_imag = np.random.normal(scale=scale, size=np.shape(data))\n",
    "    data_noisy = np.sqrt(data_real**2 + data_imag**2)\n",
    "\n",
    "    return data_noisy\n",
    "\n",
    "\n",
    "SNR = 20\n",
    "signals = add_noise(raw_signals, 1 / SNR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## (4)\n",
    "# Load data into TADRED format\n",
    "\n",
    "# Data in TADRED format, \\bar{C} measurements, M target regresors\n",
    "data = dict(\n",
    "    train=signals[0:n_train, :],  # Shape n_train x \\bar{C}\n",
    "    train_tar=parameters[0:n_train, :],  # Shape n_train x M\n",
    "    val=signals[n_train : (n_train + n_val), :],  # Shape n_val x \\bar{C}\n",
    "    val_tar=parameters[n_train : (n_train + n_val), :],  # Shape n_val x M\n",
    "    test=signals[(n_train + n_val) : (n_train + n_val + n_test), :],  # Shape n_test x \\bar{C}\n",
    "    test_tar=parameters[(n_train + n_val) : (n_train + n_val + n_test), :],  # Shape n_test x M\n",
    ")\n",
    "\n",
    "args = utils.load_base_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## (5-A)\n",
    "# Option to save data to disk, and TADRED load\n",
    "\n",
    "# Check whether a path for this model exists or not - if not create it\n",
    "proj_params = \"_simulations_\" + \"n_train_\" + str(n_train) + \"_SNR_\" + str(SNR)\n",
    "proj_name = model_name + proj_params\n",
    "\n",
    "proj_dir = Path(basedir, proj_name)\n",
    "proj_dir.mkdir(parents=True, exist_ok=True)\n",
    "np.save(Path(proj_dir, proj_name + \".npy\"), data)\n",
    "\n",
    "print(\"Saving data as\", Path(proj_dir, proj_name + \".npy\"))\n",
    "pass_data = None\n",
    "\n",
    "args.data_norm.data_fil = Path(proj_dir, proj_name + \".npy\")\n",
    "\n",
    "########## (5-B)\n",
    "# Option to pass data to JOFSTO directly\n",
    "\n",
    "pass_data = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## (6)\n",
    "# Simplest version of TADRED, modifying the most important hyperparameters\n",
    "\n",
    "\n",
    "# Decreasing feature subsets sizes for TADRED to consider\n",
    "args.tadred_train_eval.feature_set_sizes_Ci = [\n",
    "    Cbar,\n",
    "    Cbar // 2,\n",
    "    Cbar // 4,\n",
    "    Cbar // 8,\n",
    "    Cbar // 16,\n",
    "]\n",
    "\n",
    "# Feature subset sizess for TADRED evaluated on test data\n",
    "args.tadred_train_eval.feature_set_sizes_evaluated = [\n",
    "    Cbar // 2,\n",
    "    Cbar // 4,\n",
    "    Cbar // 8,\n",
    "    Cbar // 16,\n",
    "]\n",
    "\n",
    "# Scoring net Cbar -> num_units_score[0] -> num_units_score[1] ... -> Cbar units\n",
    "args.network.num_units_score = [1000, 1000]\n",
    "\n",
    "# Task net Cbar -> num_units_task[0] -> num_units_task[1] ... -> M units\n",
    "args.network.num_units_task = [1000, 1000]\n",
    "\n",
    "args.output.out_base = basedir  # \"/Users/paddyslator/python/ED_MRI/test1\" #\"/home/blumberg/Bureau/z_Automated_Measurement/Output/paddy\"\n",
    "args.output.proj_name = proj_name\n",
    "args.output.run_name = \"test\"\n",
    "args.other_options.save_output = True\n",
    "\n",
    "# tadred_args[\"total_epochs\"] = 1000\n",
    "\n",
    "TADRED_output = tadred_main.run(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also load the saved results here\n",
    "TADRED_output = np.load(\n",
    "    Path(\n",
    "        proj_dir,\n",
    "        \"results\",\n",
    "        args.output.run_name + \"_all.npy\",\n",
    "    ),\n",
    "    allow_pickle=True,\n",
    ").item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract some useful parameters fom the tadred output\n",
    "# final subset index\n",
    "\n",
    "Clast = TADRED_output[\"args\"][\"tadred_train_eval\"][\"feature_set_sizes_Ci\"][-1]\n",
    "# chosen acquisition parameters\n",
    "acq_params_tadred = acq_params_super[TADRED_output[Clast][\"measurements\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "# define CRLB functions\n",
    "\n",
    "if model_name == \"adc\":\n",
    "\n",
    "    def f_crlb(b, params, sigma):\n",
    "        # params[0] is S0\n",
    "        # params[1] is ADC\n",
    "        # params = np.zeros(2)\n",
    "        # params[0] = 1\n",
    "        # params[1] = 1\n",
    "        # sigma = 0.05\n",
    "\n",
    "        # need 2 b-values - so assume there is always a b=0 (CRLB with 2 b-values always chooses a b=0 anyway)\n",
    "        b = np.insert(b, 0, 0)\n",
    "\n",
    "        dy = np.zeros((len(b), 2))\n",
    "        dy[:, 0] = np.exp(-b * params[1])\n",
    "        dy[:, 1] = -b * params[0] * np.exp(-b * params[1])\n",
    "\n",
    "        fisher = (np.matmul(dy.T, dy)) / sigma**2\n",
    "\n",
    "        invfisher = np.linalg.inv(fisher)\n",
    "        # second diagonal element is the lower bound on the variance of the ADC\n",
    "        f = invfisher[1, 1]\n",
    "\n",
    "        return f\n",
    "\n",
    "elif model_name == \"t1inv\":\n",
    "\n",
    "    def f_crlb(ti, params, tr, sigma):\n",
    "        # params[0] is S0\n",
    "        # params[1] is T1\n",
    "        # convert to R1\n",
    "        params[1] = 1 / params[1]\n",
    "        # tr = 7\n",
    "        # sigma = 1\n",
    "\n",
    "        dy = np.zeros((len(ti), 2))\n",
    "        dy[:, 0] = 1 - 2 * np.exp(-ti * params[1]) + np.exp(-tr * params[1])\n",
    "        dy[:, 1] = params[0] * (2 * ti * np.exp(-ti * params[1]) - tr * np.exp(-tr * params[1]))\n",
    "\n",
    "        fisher = (np.matmul(dy.T, dy)) / sigma**2\n",
    "\n",
    "        invfisher = np.linalg.inv(fisher)\n",
    "        # second diagonal element is the lower bound on the variance of R1\n",
    "        f = invfisher[1, 1]\n",
    "\n",
    "        return f\n",
    "\n",
    "\n",
    "# calculate CRLB optimal acquisition parameter (e.g. b-value, TI) for a range of model parameters (e.g. ADC, T1)\n",
    "# match number of model parameters in the range to the number of measurements in the final TADRED output\n",
    "\n",
    "# Calculate the range of parameters\n",
    "if model_name == \"adc\":\n",
    "    params = np.linspace(0, maxD, Clast)[1:]  # one less parameter for ADC as CRLB assumes a b=0\n",
    "elif model_name == \"t1inv\":\n",
    "    params = np.linspace(0, maxT1, Clast + 1)[1:]\n",
    "\n",
    "# initialise array of CRLB-optimsed acquisition parameters (e.g. b-values, TI)\n",
    "acq_params_crlb = np.zeros(Clast)\n",
    "\n",
    "# these don't affect the optimisation so can be fixed\n",
    "S0 = 1\n",
    "sigma = 1 / SNR\n",
    "\n",
    "for i in range(0, len(params)):\n",
    "    if model_name == \"adc\":\n",
    "        fixed_args = (np.array((S0, params[i])), sigma)\n",
    "        bnds = ((minb, maxb),)\n",
    "        init = 1 / params[i]\n",
    "    #        init = np.array((1/params[i],2/params[i]))\n",
    "    elif model_name == \"t1inv\":\n",
    "        fixed_args = (np.array((S0, params[i])), tr, sigma)\n",
    "        bnds = ((minti, maxti),)\n",
    "        init = params[i]\n",
    "\n",
    "    acq_params_crlb[i] = minimize(\n",
    "        f_crlb, init, args=fixed_args, method=\"Nelder-Mead\", bounds=bnds\n",
    "    ).x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #calculate robust CRLB by summing over many possible D/T1's McHugh et al. MRM 2018 doi: 10.1002/mrm.27551\n",
    "# take the first 100 parameters (as in McHugh)\n",
    "# parameters_robust = parameters[0:100]\n",
    "\n",
    "# def f_crlb_robust(b,S0,parameters_robust,sigma):\n",
    "#     for param in parameters_robust:\n",
    "#         f_summand = f_crlb(b,np.array((S0,param),dtype=object),sigma)\n",
    "\n",
    "#     return np.sum(np.log(f_summand))\n",
    "\n",
    "\n",
    "# if model_name == 'adc':\n",
    "#     fixed_args = (S0,parameters_robust,sigma)\n",
    "#     bnds=((minb,maxb),)\n",
    "#     init = 1/params[i]\n",
    "#     init = np.array((1/params[i],2*params[i],3*params[i]))\n",
    "# elif model_name == 't1inv':\n",
    "#     fixed_args = (S0,parameters_robust, tr, sigma)\n",
    "#     bnds=((minti,maxti),)\n",
    "#     init = params[i]\n",
    "\n",
    "\n",
    "# acq_params_CRLB_robust = minimize(f_crlb_robust, np.linspace(minb,maxb,C_last), args=fixed_args, method='Nelder-Mead',bounds=bnds).x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the TADRED and CRLB acquisition parameters (e.g. b-values, TI,...)\n",
    "# all super-design acquisition parameters\n",
    "paramtest = params[5]\n",
    "\n",
    "print(acq_params_super.shape, model(paramtest, acq_params_super).shape)\n",
    "\n",
    "if model_name == \"adc\":\n",
    "    # all super-design b-values\n",
    "    plt.plot(acq_params_super, model(paramtest, acq_params_super), \"k.\", markersize=2)\n",
    "    # TADRED chosen b-values\n",
    "    C_last = TADRED_output[\"args\"][\"tadred_train_eval\"][\"feature_set_sizes_evaluated\"][-1]\n",
    "    plt.plot(\n",
    "        acq_params_tadred,\n",
    "        model(paramtest, acq_params_tadred),\n",
    "        \"bs\",\n",
    "        fillstyle=\"none\",\n",
    "        markeredgewidth=2,\n",
    "    )\n",
    "    # CRLB chosen b-values\n",
    "    plt.plot(acq_params_crlb, model(paramtest, acq_params_crlb), \"rs\", fillstyle=\"none\")\n",
    "    plt.legend([\"super-design\", \"TADRED\", \"CRLB\"], fontsize=14)\n",
    "    plt.xlabel(\"b-value ($\\mu$m$^2$ s$^{-1}$)\", fontsize=14)\n",
    "elif model_name == \"t1inv\":\n",
    "    # all super-design b-values\n",
    "    plt.plot(acq_params_super, model(paramtest, acq_params_super, tr), \"k.\", markersize=2)\n",
    "    # TADRED chosen b-values\n",
    "    C_last = TADRED_output[\"args\"][\"tadred_train_eval\"][\"feature_set_sizes_evaluated\"][-1]\n",
    "    plt.plot(\n",
    "        acq_params_tadred,\n",
    "        model(paramtest, acq_params_tadred, tr),\n",
    "        \"bs\",\n",
    "        fillstyle=\"none\",\n",
    "        markeredgewidth=2,\n",
    "    )\n",
    "    # CRLB chosen b-values\n",
    "    plt.plot(acq_params_crlb, model(paramtest, acq_params_crlb, tr), \"r.\", markeredgewidth=3)\n",
    "    plt.legend([\"Super design\", \"TADRED\", \"CRLB\"], fontsize=14)\n",
    "    plt.xlabel(\"Inversion time (s)\", fontsize=14)\n",
    "\n",
    "\n",
    "plt.ylabel(\"Signal\", fontsize=14)\n",
    "\n",
    "# define location to save figures\n",
    "fig_dir = Path(proj_dir, \"figures\")\n",
    "fig_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# base filename for saving figures\n",
    "fig_basename = model_name + \"_simulations_n_train_\" + str(n_train) + \"_\" + str(SNR)\n",
    "\n",
    "plt.savefig(Path(fig_dir, fig_basename + \"_acq_params.png\"), dpi=300)\n",
    "plt.savefig(Path(fig_dir, fig_basename + \"_acq_params.eps\"), dpi=300)\n",
    "plt.savefig(Path(fig_dir, fig_basename + \"_acq_params.pdf\"), dpi=300)\n",
    "\n",
    "\n",
    "print(\n",
    "    'TO DO: move this to the plotting function and plot for all SNR. In text: \"we examine the chosen acquisition schemes for the simple models\"'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions for model fitting\n",
    "\n",
    "\n",
    "def rician_log_likelihood(signals, synth_signals, sigma):\n",
    "    sumsqsc = (signals**2 + synth_signals**2) / (2 * sigma**2)\n",
    "    #    print(\"sumsqsc: \" + str(sumsqsc))\n",
    "    scp = synth_signals * signals / sigma**2\n",
    "    #    print(\"scp: \" + str(scp))\n",
    "    #    lb0 = np.log(np.i0(scp))\n",
    "    lb0 = log_i0(scp)\n",
    "    #    print(\"lb0: \" + str(lb0))\n",
    "    log_likelihoods = -2 * np.log(sigma) - sumsqsc + np.log(synth_signals) + lb0\n",
    "    #    print(\"log_likelihoods: \" + str(log_likelihoods))\n",
    "\n",
    "    return np.sum(log_likelihoods)\n",
    "\n",
    "\n",
    "if model_name == \"adc\":\n",
    "\n",
    "    def rician_objective_function(D, bvals, signals, sigma):\n",
    "        return -rician_log_likelihood(model(D, bvals), signals, sigma)\n",
    "\n",
    "    def gaussian_objective_function(D, bvals, signals):\n",
    "        return np.mean((signals - model(D, bvals)) ** 2)\n",
    "\n",
    "elif model_name == \"t1inv\":\n",
    "\n",
    "    def rician_objective_function(T1, ti, tr, signals, sigma):\n",
    "        return -rician_log_likelihood(model(T1, ti, tr), signals, sigma)\n",
    "\n",
    "    def gaussian_objective_function(T1, ti, tr, signals):\n",
    "        return np.mean((signals - model(T1, ti, tr)) ** 2)\n",
    "\n",
    "\n",
    "def log_i0(x):\n",
    "    exact = x < 700\n",
    "    approx = x >= 700\n",
    "\n",
    "    lb0 = np.zeros(np.shape(x))\n",
    "    lb0[exact] = np.log(np.i0(x[exact]))\n",
    "    # This is a more standard approximation.  For large x, I_0(x) -> exp(x)/sqrt(2 pi x).\n",
    "    lb0[approx] = x[approx] - np.log(2 * np.pi * x[approx]) / 2\n",
    "\n",
    "    return lb0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "# fit the model on the super-design acquisition, TADRED acquisition, CRLB acquisition\n",
    "\n",
    "# choose the noise level\n",
    "sigma_test = 1 / SNR  # set to the level of the training data simulations\n",
    "# sigma_test = 0.2 #set to something else\n",
    "\n",
    "\n",
    "# for the super design use the test data signals - but with different noise\n",
    "raw_signals_super = signals[(n_train + n_val) : (n_train + n_val + n_test), :]\n",
    "signals_super = add_noise(raw_signals_super, sigma_test)\n",
    "\n",
    "# for tadred use the reconstructed data\n",
    "signals_tadred = signals[\n",
    "    (n_train + n_val) : (n_train + n_val + n_test),\n",
    "    TADRED_output[C_last][\"measurements\"],\n",
    "]\n",
    "\n",
    "\n",
    "# for CRLB simulate data for the CRLB acquisition - as don't have test data at these b-values\n",
    "signals_crlb = np.zeros((n_test, C_last))\n",
    "# use the ground truth parameters from the test dataset\n",
    "gt_parameters = data[\"test_tar\"][:, 0]\n",
    "for i in range(0, n_test):\n",
    "    if model_name == \"adc\":\n",
    "        signals_crlb[i, :] = add_noise(model(gt_parameters[i], acq_params_crlb), scale=sigma_test)\n",
    "    if model_name == \"t1inv\":\n",
    "        signals_crlb[i, :] = add_noise(\n",
    "            model(gt_parameters[i], acq_params_crlb, tr), scale=sigma_test\n",
    "        )\n",
    "\n",
    "\n",
    "# choose starting parameter value for the fit - this should work fine for both models\n",
    "paramstart = 2\n",
    "\n",
    "fitted_parameters_crlb = np.zeros(n_test)\n",
    "fitted_parameters_super = np.zeros(n_test)\n",
    "fitted_parameters_tadred = np.zeros(n_test)\n",
    "\n",
    "\n",
    "# fit the models to the data\n",
    "# Note that we pass the ground truth sigma to the fitting methods - but TADRED_NN never sees the ground truth sigma\n",
    "for i in range(0, n_test):\n",
    "    if model_name == \"adc\":\n",
    "        fitted_parameters_crlb[i] = minimize(\n",
    "            rician_objective_function,\n",
    "            paramstart,\n",
    "            args=(acq_params_crlb, signals_crlb[i, :], sigma_test),\n",
    "            method=\"Nelder-Mead\",\n",
    "        ).x\n",
    "        fitted_parameters_super[i] = minimize(\n",
    "            rician_objective_function,\n",
    "            paramstart,\n",
    "            args=(acq_params_super, signals_super[i, :], sigma_test),\n",
    "            method=\"Nelder-Mead\",\n",
    "        ).x\n",
    "        fitted_parameters_tadred[i] = minimize(\n",
    "            rician_objective_function,\n",
    "            paramstart,\n",
    "            args=(acq_params_tadred, signals_tadred[i, :], sigma_test),\n",
    "            method=\"Nelder-Mead\",\n",
    "        ).x\n",
    "    if model_name == \"t1inv\":\n",
    "        fitted_parameters_crlb[i] = minimize(\n",
    "            rician_objective_function,\n",
    "            paramstart,\n",
    "            args=(acq_params_crlb, tr, signals_crlb[i, :], sigma_test),\n",
    "            method=\"Nelder-Mead\",\n",
    "        ).x\n",
    "        fitted_parameters_super[i] = minimize(\n",
    "            rician_objective_function,\n",
    "            paramstart,\n",
    "            args=(acq_params_super, tr, signals_super[i, :], sigma_test),\n",
    "            method=\"Nelder-Mead\",\n",
    "        ).x\n",
    "        fitted_parameters_tadred[i] = minimize(\n",
    "            rician_objective_function,\n",
    "            paramstart,\n",
    "            args=(acq_params_tadred, tr, signals_tadred[i, :], sigma_test),\n",
    "            method=\"Nelder-Mead\",\n",
    "        ).x\n",
    "\n",
    "\n",
    "# extract the TADRED nn fit\n",
    "fitted_parameters_tadred_nn = TADRED_output[args.tadred_train_eval.feature_set_sizes_Ci[-1]][\n",
    "    \"test_output\"\n",
    "][:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This needs to be cleaned up\n",
    "\n",
    "# save the ground truth parameters, signals, and fitted parameters for plotting later (ground truth is saved as \"data\" above)\n",
    "\n",
    "# crlb test signals\n",
    "np.save(Path(proj_dir, \"signals_crlb.npy\"), signals_crlb)\n",
    "\n",
    "print(Path(proj_dir, \"signals_crlb.npy\"))\n",
    "\n",
    "# super design test signals - already saved as \"data\" dictionary above but also save here for neatness\n",
    "np.save(Path(proj_dir, \"signals_super.npy\"), signals_super)\n",
    "\n",
    "# tadred recon test signals - also saved in the tadred output but also save separately for neatness\n",
    "np.save(Path(proj_dir, \"signals_tadred.npy\"), signals_tadred)\n",
    "\n",
    "# save lsq fits\n",
    "np.save(Path(proj_dir, \"fit_crlb.npy\"), fitted_parameters_crlb)\n",
    "np.save(Path(proj_dir, \"fit_super.npy\"), fitted_parameters_super)\n",
    "np.save(Path(proj_dir, \"fit_tadred_lsq.npy\"), fitted_parameters_tadred)\n",
    "\n",
    "# save tadred nn fits\n",
    "np.save(Path(proj_dir, \"fit_tadred_nn.npy\"), fitted_parameters_tadred_nn)\n",
    "\n",
    "# save test dataset ground truth parameters\n",
    "np.save(Path(proj_dir, \"parameters_gt.npy\"), gt_parameters)\n",
    "\n",
    "# super design full dataset signals - already saved as \"data\" dictionary above, save again TODO why?\n",
    "np.save(Path(proj_dir, \"signals_super_full.npy\"), signals)\n",
    "\n",
    "# save full dataset ground truth parameters\n",
    "np.save(Path(proj_dir, \"parameters_gt_full.npy\"), parameters)\n",
    "\n",
    "# save super design acquisition parameters\n",
    "np.save(Path(proj_dir, \"acq_params_super.npy\"), acq_params_super)\n",
    "\n",
    "# save CRLB acquisition parameters\n",
    "np.save(Path(proj_dir, \"acq_params_crlb.npy\"), acq_params_crlb)\n",
    "\n",
    "# save TADRED acquisition parameters\n",
    "np.save(Path(proj_dir, \"acq_params_tadred.npy\"), acq_params_tadred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## (7)\n",
    "# Modify more TADRED hyperparameters, less important, may change results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## (8)\n",
    "# Deep learning training hyperparameters for inner loop"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "615b1a4c774898c50e50cbbdb62428ce29922c4c76c6af0df5092a4f94b8ccac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
