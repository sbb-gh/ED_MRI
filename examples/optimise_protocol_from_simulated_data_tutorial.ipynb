{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of acquisition volumes for the optimised protocol and the number TADRED iterations.\n",
    "# Recall from paper we train on iteratively smaller volume sizes across a loop t = 1, ..., T\n",
    "# This determines the length of the superdesign required for the training set, e.g. if n_iterations_tadred\n",
    "# is 5 then the superdesign needs to be 16 times larger than the number of volumes in the optimised protocol\n",
    "\n",
    "# TODO doesn't it make more sense to put this where we select the subsets? unless if this is the main part we want the user to vary\n",
    "\n",
    "n_volumes_opt_protocol = 20\n",
    "n_iterations_tadred = 5 # T in paper\n",
    "\n",
    "print(f\"Length of desired optimised protocol: {n_volumes_opt_protocol}\")\n",
    "print(f\"Number of TADRED iterations: {n_iterations_tadred}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the required length of the superdesign, this depends on the number of \n",
    "# this depends on the number of TADRED iterations - which are always halvings - that will be done in tadred\n",
    "Vbar = n_volumes_opt_protocol * 2**(n_iterations_tadred - 1) #\n",
    "\n",
    "print(\"Size of the required superdesign for the simulations: {Vbar}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## (1)\n",
    "# See requirements.txt for tadred requirements, make sure things are in the path, set global seed\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "from tadred import tadred_main, utils\n",
    "\n",
    "# Replace below with directory data already is, or whre you want to save the data and results \n",
    "out_base: str = '/home/blumberg/Bureau/z_Automated_Measurement/Output/journal_paper_tst' # ''\n",
    "Path(out_base).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# If TADRED is installed in another directory, add the location tobelow\n",
    "# TADRED_dir: str = ''\n",
    "# sys.path.append(TADRED_dir)\n",
    "\n",
    "np.random.seed(0)  # Random seed for entire script\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## (2)\n",
    "# Data split sizes\n",
    "\n",
    "n_train_voxels = 10**4  # Reduce for faster training speed\n",
    "n_val_voxels = n_train_voxels // 10\n",
    "n_test_voxels = n_train_voxels // 10\n",
    "n_samples = n_train_voxels + n_val_voxels + n_test_voxels  # total number of samples to simulate\n",
    "\n",
    "use_own_simulated_data: bool = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you are using your own simulated data, follow the guidelines to \n",
    "#generate simulated data that is appropriate for input to TADRED\n",
    "\n",
    "# TODO this should be in the introduction where we define what the data looks like.  Or in a different repo.\n",
    "\n",
    "if use_own_simulated_data:\n",
    "    print(\n",
    "        f\"\"\"\n",
    "        You need to simulate the following data to run TADRED\n",
    "        Ground truth parameters vector of size n_samples by n_model_parameters\n",
    "        Where:\n",
    "            n_samples is {n_samples}\n",
    "            n_model_parameters is the number of parameters in your model\n",
    "        \n",
    "        Simulated ground truth signals with superdesign acquisition scheme of size n_samples by Vbar\n",
    "        Where:\n",
    "            The superdesign acquisition scheme highly oversamples the available acquisition parameter space\n",
    "            Vbar is the superdesign length {Vbar}\n",
    "        \n",
    "        Acquisition parameters of the superdesign of size Vbar by n_acquisition_parameters\n",
    "        Where:\n",
    "            n_acqusition_parameters is the dimension of the acquisition parameter space, e.g. 4 (gx, gy, gz, b) for HCP data\n",
    "        \n",
    "        Save the data as .npy files.\n",
    "        Suggested filenames:\n",
    "            parameter array: parameters_gt_full.npy\n",
    "            simulated signals: signals_super_full.npy\n",
    "            acquisition parameters: acq_params_super.npy\n",
    "    \"\"\"\n",
    "    )\n",
    "else:\n",
    "    print(f'Run the cell below to simulate data suitable for TADRED')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some models and generate data\n",
    "# Data that will be generated is:\n",
    "#   parameters - n_samples by n_model_parameters  array containing the ground truth model parameters, where n_parameters is the number of parameters in your model\n",
    "#   signals - n_samples by Vbar array containing the corresponding simulated signals from the model \n",
    "#   acq_params_super - Vbar by n_acqusition_parameters length array containing the acquisition parameters of the superdesign\n",
    "\n",
    "model_name = 't1inv' # T1 inversion recovery model\n",
    "# model_name = \"adc\" # ADC model\n",
    "SNR: int = 20\n",
    "proj_name = f\"{model_name}_simulations_n_train_voxels_{n_train_voxels}_SNR_{SNR}\"\n",
    "proj_dir = Path(out_base, proj_name)\n",
    "Path.mkdir(proj_dir, exist_ok=True, parents=True)\n",
    "\n",
    "if not use_own_simulated_data:\n",
    "        \n",
    "    if model_name == \"adc\":\n",
    "        def model(D, bvals):\n",
    "            signals = np.exp(-bvals * D)\n",
    "            return signals\n",
    "    \n",
    "        # min/max parameter values\n",
    "        minD = 0.1\n",
    "        maxD = 3\n",
    "    \n",
    "        # Simulate parameter values\n",
    "        parameters = np.random.uniform(low=minD, high=maxD, size=(n_samples, 1))\n",
    "    \n",
    "        ### Generate data using the model\n",
    "    \n",
    "        # Make super design\n",
    "        maxb = 5\n",
    "        minb = 0\n",
    "        acq_params_super = np.linspace(minb, maxb, Vbar)\n",
    "    \n",
    "        # Generate data\n",
    "        raw_signals = np.zeros((n_samples, Vbar), dtype=np.float32)\n",
    "        for i in range(0, n_samples):\n",
    "            raw_signals[i, :] = model(parameters[i], acq_params_super)\n",
    "    \n",
    "    elif model_name == \"t1inv\":\n",
    "    \n",
    "        def model(T1, ti, tr):\n",
    "            signals = abs(1 - (2 * np.exp(-ti / T1)) + np.exp(-tr / T1))\n",
    "            return signals\n",
    "    \n",
    "        # min/max parameter values\n",
    "        minT1 = 0.1\n",
    "        maxT1 = 7\n",
    "        # Simulate parameter values\n",
    "        parameters = np.random.uniform(low=minT1, high=maxT1, size=(n_samples, 1))\n",
    "        \n",
    "        # Make the super design\n",
    "        tr = 7  # repetition time\n",
    "        maxti = tr\n",
    "        minti = 0.1\n",
    "        acq_params_super = np.linspace(minti, maxti, Vbar)\n",
    "    \n",
    "        # Generate the data\n",
    "        raw_signals = np.zeros((n_samples, Vbar), dtype=np.float32)\n",
    "        for i in range(0, n_samples):\n",
    "            raw_signals[i, :] = model(parameters[i], acq_params_super, tr)\n",
    "\n",
    "    # Add Rician noise to the data\n",
    "    def add_noise(data, scale=0.05):\n",
    "        data_real = data + np.random.normal(scale=scale, size=np.shape(data))\n",
    "        data_imag = np.random.normal(scale=scale, size=np.shape(data))\n",
    "        data_noisy = np.sqrt(data_real**2 + data_imag**2)\n",
    "    \n",
    "        return data_noisy\n",
    "    \n",
    "    signals_super = add_noise(raw_signals, 1 / SNR)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO this cell doesn't make any sense, what are you meant to be loadikng and why?\n",
    "# TODO maybe keep this notebook for simulations only\n",
    "\n",
    "if use_own_simulated_data:\n",
    "    # Replace with project name\n",
    "    proj_name: str = 'TADRED_test'\n",
    "\n",
    "    # REPLACE WITH PATH TO SIMULATION GROUND TRUTH PARAMETERS\n",
    "    # Saved array should be array n_samples by n_model_parameters     \n",
    "    simulation_gt_parameters_path = Path(proj_name,'parameters_gt_full.npy')\n",
    "    \n",
    "    # REPLACE WITH PATH TO SIMULATION GROUND TRUTH SIGNALS WITH \"SUPER-DESIGN\" ACQUISITION - HIGHLY OVERSAMPLING THE ACQUISITION PARAMETER SPACE\n",
    "    # Array is n_samples by V_bar\n",
    "    simulation_gt_signals_path = Path(proj_name, 'signals_super_full.npy')\n",
    "    \n",
    "    # REPLACE WITH PATH TO SUPER-DESIGN ACQUISITION PARAMETERS\n",
    "    # acq_params_super - Vbar by n_acqusition_parameters length array containing the acquisition parameters of the superdesign\n",
    "\n",
    "    \n",
    "    # Array is Vbar by n_acqusition_parameters, e.g. n_acqusition_parameters is 4 (gx, gy, gz, b) for HCP data\n",
    "    acq_params_super_signals_path = Path(proj_name, 'acq_params_super.npy')\n",
    "    \n",
    "    # Load the files\n",
    "    parameters = np.load(simulation_gt_parameters_path)\n",
    "    signals_super = np.load(simulation_gt_signals_path)\n",
    "    acq_params_super = np.load(acq_params_super_signals_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## (3-A)\n",
    "# Create dummy, randomly generated (positive) data\n",
    "\n",
    "# C_bar = 220\n",
    "# M = 12  # Number of input measurements \\bar{C}, Target regressors\n",
    "# rand = np.random.lognormal  # Random genenerates positive\n",
    "# train_inp, train_tar = rand(size=(n_train_voxels, C_bar)), rand(size=(n_train_voxels, M))\n",
    "# val_inp, val_tar = rand(size=(n_val, C_bar)), rand(size=(n_val, M))\n",
    "# test_inp, test_tar = rand(size=(n_test_voxels, C_bar)), rand(size=(n_test_voxels, M))\n",
    "\n",
    "\n",
    "# #########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## (4)\n",
    "# Load data into TADRED format\n",
    "\n",
    "print(signals_super)\n",
    "\n",
    "# Data in TADRED format, \\bar{V} volumes, M target regresors\n",
    "data = dict(\n",
    "    train=signals_super[0:n_train_voxels, :],  # Shape n_train_voxels x \\bar{C}\n",
    "    train_tar=parameters[0:n_train_voxels, :],  # Shape n_train_voxels x M\n",
    "    val=signals_super[n_train_voxels : (n_train_voxels + n_val_voxels), :],  # Shape n_val_voxels x \\bar{C}\n",
    "    val_tar=parameters[n_train_voxels : (n_train_voxels + n_val_voxels), :],  # Shape n_val_voxels x M\n",
    "    test=signals_super[(n_train_voxels + n_val_voxels): , :],  # Shape n_test_voxels x \\bar{C}\n",
    "    test_tar=parameters[(n_train_voxels + n_val_voxels):, :],  # Shape n_test_voxels x M\n",
    ")\n",
    "\n",
    "for key, value in data.items():\n",
    "    data[key] = value.astype(np.float32)\n",
    "\n",
    "# Save data to disk -- optional\n",
    "np.save(Path(proj_dir, 'data'), data)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## (6)\n",
    "# Simplest version of TADRED, modifying the most important hyperparameters\n",
    "# The decreasing subset sizes are hard-coded so final optimized protocol is 1/16 the size of the superdesign\n",
    "# Feel free to play around with the subset size reduction pattern, \n",
    "# halving the size of the subset sizes at each TADRED step seems to generally work well.\n",
    "\n",
    "args = utils.load_base_args()\n",
    "\n",
    "args.tadred_train_eval.feature_set_sizes_Ci = [Vbar // (2**i) for i in range(n_iterations_tadred)]\n",
    "args.tadred_train_eval.feature_set_sizes_evaluated = [Vbar // (2**i) for i in range(1, n_iterations_tadred)]\n",
    "\n",
    "# Scoring net Vbar -> num_units_score[0] -> num_units_score[1] ... -> Vbar units\n",
    "args.network.num_units_score: list[int] = [1000, 1000]\n",
    "\n",
    "# Task net Vbar -> num_units_task[0] -> num_units_task[1] ... -> M units\n",
    "args.network.num_units_task: list[int] = [1000, 1000]\n",
    "\n",
    "# SBB TODO add Pathlib option to tadred.utils.py:create_out_dirs\n",
    "args.output.out_base = str(out_base)  # \"/Users/paddyslator/python/ED_MRI/test1\" #\"/home/blumberg/Bureau/z_Automated_Measurement/Output/paddy\"\n",
    "args.output.proj_name = str(proj_name)\n",
    "args.output.run_name = \"test\"\n",
    "args.other_options.save_output = True\n",
    "\n",
    "#print(args)\n",
    "\n",
    "args.tadred_train_eval.epochs = 50\n",
    "\n",
    "print(out_base, proj_name)\n",
    "\n",
    "TADRED_output = tadred_main.run(args, data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also load the saved results here\n",
    "# TADRED_output = np.load(\n",
    "#     Path(\n",
    "#         proj_dir,\n",
    "#         \"results\",\n",
    "#         args.output.run_name + \"_all.npy\",\n",
    "#     ),\n",
    "#     allow_pickle=True,\n",
    "# ).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract some useful parameters fom the tadred output\n",
    "# final subset index\n",
    "V_last = TADRED_output[\"args\"][\"tadred_train_eval\"][\"feature_set_sizes_Ci\"][-1] # V_{T} in paper\n",
    "\n",
    "# Index of chosen acquisition parameters\n",
    "acq_params_tadred_index = TADRED_output[V_last][\"measurements\"]\n",
    "\n",
    "# Chosen acquisition parameters\n",
    "acq_params_tadred = acq_params_super[acq_params_tadred_index]\n",
    "\n",
    "print(f\"TADRED chosen acquisition parameters are: {acq_params_tadred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the signals at the super design and the tadred chosen for a single voxel\n",
    "#\n",
    "\n",
    "#if the number of acquisition parameters is bigger than one, need to choose which one to plot on the x axis\n",
    "if (acq_params_super.ndim > 1): \n",
    "    if (acq_params_super.shape[1] > 1):\n",
    "        acq_param_to_plot = 1\n",
    "        acq_params_super_to_plot = acq_params_super[:,acq_param_to_plot]\n",
    "        acq_params_tadred_to_plot = acq_params_tadred[:,acq_param_to_plot]\n",
    "        acq_params_tadred_index_to_plot = acq_params_tadred_index[:,acq_param_to_plot]\n",
    "else:\n",
    "    acq_params_super_to_plot = acq_params_super\n",
    "    acq_params_tadred_to_plot = acq_params_tadred\n",
    "    acq_params_tadred_index_to_plot = acq_params_tadred_index\n",
    "    \n",
    "voxel_to_plot = 0\n",
    "\n",
    "\n",
    "plt.plot(acq_params_super_to_plot, signals_super[voxel_to_plot,:], 'x')\n",
    "plt.plot(acq_params_tadred_to_plot, signals_super[voxel_to_plot,acq_params_tadred_index], 'o')\n",
    "\n",
    "plt.title('signals from voxel ' + str(voxel_to_plot))\n",
    "plt.legend(('Super design', 'TADRED chosen'))\n",
    "plt.ylabel('signal')\n",
    "plt.xlabel('acquisition parameter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save TADRED acquisition parameters\n",
    "#np.save(Path(proj_, \"acq_params_tadred.npy\"), acq_params_tadred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "615b1a4c774898c50e50cbbdb62428ce29922c4c76c6af0df5092a4f94b8ccac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
