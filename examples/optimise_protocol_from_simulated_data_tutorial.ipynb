{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Optimising a Quantitative MRI Protocol Using Simulated Data\n",
    "\n",
    "This notebook demonstrates how to use TADRED to optimise a quantitative or diffusion MRI protocol using simulated data. The code can be adapted to optimise protocols for your chosen model, whether it's analytical or another type.\n",
    "\n",
    "To use your own model, simulate data using it while adhering to the key caveats outlined throughout this notebook.\n",
    "\n",
    "### Key User-Defined Quantities:\n",
    "\n",
    "1. **Protocol Length (`n_volumes_opt`)**: Define the number of acquisition parameters or acquired volumes for your optimised protocol.\n",
    "\n",
    "2. **Number of Divisions (`n_divisions_tadred`)**: Set the number of divisions for the subset size that TADRED will use during training. The default is 5, which typically works well.\n",
    "\n",
    "3. **Number of Training Voxels (`n_train`)**: Specify the number of training voxels. Reduce this number for faster training or increase it for more accuracy.\n",
    "\n",
    "### Simulation Requirements:\n",
    "\n",
    "1. **Superdesign Size**: Parameters 1 and 2 determine the size of the superdesign required for simulations. In this tutorial, TADRED will sequentially halve the number of subsets. For example, with `n_volumes_opt=20` and `n_divisions_tadred=5`, the subsetting will be `[320, 160, 80, 40, 20]`. Therefore, the superdesign acquisition should include 320 acquisitions. The acquisition parameters of the superdesign should span the entire acquisition space from which optimal parameters will be selected. For instance, if your scanner has a maximum b-value of 3000, the superdesign might include 320 b-values equally spaced between 0 and 3000. This principle generalises to higher dimensions.\n",
    "\n",
    "2. **Simulated Voxels**: Parameter 3 defines the number of simulated voxels needed. If `n_train=1000`, then 1200 voxels are required in total, as 100 voxels are allocated for the validation dataset and 100 for the test dataset.\n",
    "\n",
    "Cell X provides an example of how to run the appropriate simulations for two simple models.\n",
    "\n",
    "(c) Stefano B. Blumberg and Paddy J. Slator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of acquisition volumes for the optimised protocol and the number of subset divisions in TADRED\n",
    "# These values will determine the length of the superdesign required for the training set\n",
    "# E.g. If n_divisions_tadred is 5 then the superdesign needs to be 16 times larger than the number of volumes in the optimised protocol\n",
    "\n",
    "n_volumes_opt = 20  # Number of volumes in the optimised protocol\n",
    "\n",
    "n_divisions_tadred = 5 #number of divisions to run in TADRED\n",
    "\n",
    "print(\"Length of desired optimised protocol: \" + str(n_volumes_opt))\n",
    "print(\"Number of TADRED subset divisions: \" + str(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the required length of the superdesign\n",
    "#this depends on the number of subset divisions - which are always halvings - that will be done in tadred\n",
    "Cbar = n_volumes_opt * 2**(n_divisions_tadred-1) #\n",
    "\n",
    "print(\"Size of the required superdesign for the simulations: \" + str(Cbar))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## (1)\n",
    "# Import modules, see requirements.txt for tadred requirements, make sure things are in the path, set global seed\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import yaml \n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "#replace with the top level ED_MRI install directory\n",
    "EDMRIDIR = '/Users/scmps8/repos/github.com/ED_MRI/'\n",
    "#TADRED should be installed in the ED_MRI directory  \n",
    "TADREDDIR = os.path.join(EDMRIDIR,'tadred') #'/Users/scmps8/repos/github.com/ED_MRI/tadred'\n",
    "\n",
    "# Make sure both directories are on sys.path\n",
    "sys.path.append(EDMRIDIR)\n",
    "sys.path.append(TADREDDIR)\n",
    "\n",
    "#import TADRED code\n",
    "from tadred import tadred_main, utils\n",
    "\n",
    "np.random.seed(0)  # Random seed for entire script\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories and filenames to save data (Replace with location of TADRED code - possible to get this automatically?)\n",
    "basedir = EDMRIDIR\n",
    "#if directory isn't defined then just use the current working directory\n",
    "try:\n",
    "    basedir\n",
    "except NameError:\n",
    "    basedir = os.getcwd()\n",
    "    print('data will be saved in the current working directory')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## (2)\n",
    "# Data split sizes\n",
    "\n",
    "n_train = 10**4  # No. training voxels, reduce for faster training speed\n",
    "n_val = n_train // 10  # No. validations set voxels\n",
    "n_test = n_train // 10  # No. test set voxels\n",
    "\n",
    "n_samples = n_train + n_val + n_test  # total number of samples to simulate\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you are using your own simulated data, follow the guidelines to \n",
    "#generate simulated data that is appropriate for input to TADRED\n",
    "\n",
    "use_own_simulated_data = True\n",
    "\n",
    "if use_own_simulated_data:\n",
    "    print('You need to simulate the following data to run TADRED.')\n",
    "    print('Ground truth parameters vector of size n_samples by n_model_parameters')\n",
    "    print('Where:')\n",
    "    print('n_samples is ' + str(n_samples))\n",
    "    print('n_model_parameters is the number of parameters in your model')\n",
    "    \n",
    "    print('Simulated ground truth signals with superdesign acquisition scheme of size n_samples by Cbar')\n",
    "    print('Where:')\n",
    "    print('The superdesign acquisition scheme highly oversamples the available acquisition parameter space')\n",
    "    print('Cbar is the superdesign length ' + str(Cbar))\n",
    "    \n",
    "    print('Acquisition parameters of the superdesign of size Cbar by n_acquisition_parameters')\n",
    "    print('Where:')\n",
    "    print('n_acqusition_parameters is the dimension of the acquisition parameter space, e.g. 4 (gx, gy, gz, b) for HCP data')\n",
    "    \n",
    "    print('Save the data as .npy files.')\n",
    "    print('Suggested filenames:')\n",
    "    print('parameter array: parameters_gt_full.npy')\n",
    "    print('simulated signals: signals_super_full.npy')\n",
    "    print('acquisition parameters: acq_params_super.npy')\n",
    "else:\n",
    "    print('Run the cell below to simulate data suitable for TADRED')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define some models and generate the data\n",
    "#The data that will be generated is:\n",
    "#parameters - n_samples by n_model_parameters  array containing the ground truth model parameters, where n_parameters is the number of parameters in your model\n",
    "#signals - n_samples by Cbar array containing the corresponding simulated signals from the model \n",
    "#acq_params_super - Cbar by n_acqusition_parameters length array containing the acquisition parameters of the superdesign\n",
    "\n",
    "if not use_own_simulated_data:\n",
    "\n",
    "    model_name = 't1inv'\n",
    "    # model_name = \"adc\"\n",
    "    \n",
    "    if model_name == \"adc\":\n",
    "        # model equation for simulation\n",
    "        def model(D, bvals):\n",
    "            signals = np.exp(-bvals * D)\n",
    "            return signals\n",
    "    \n",
    "        # min/max parameter values\n",
    "        minD = 0.1\n",
    "        maxD = 3\n",
    "    \n",
    "        # simulate parameter values\n",
    "        parameters = np.random.uniform(low=minD, high=maxD, size=(n_samples, 1))\n",
    "    \n",
    "        # Generate data using the model\n",
    "    \n",
    "        # make the super design\n",
    "        maxb = 5\n",
    "        minb = 0\n",
    "        acq_params_super = np.linspace(minb, maxb, Cbar)\n",
    "    \n",
    "        # generate the data\n",
    "        raw_signals = np.zeros((n_samples, Cbar), dtype=np.float32)\n",
    "        for i in range(0, n_samples):\n",
    "            raw_signals[i, :] = model(parameters[i], acq_params_super)\n",
    "    \n",
    "    \n",
    "    elif model_name == \"t1inv\":\n",
    "    \n",
    "        def model(T1, ti, tr):\n",
    "            signals = abs(1 - (2 * np.exp(-ti / T1)) + np.exp(-tr / T1))\n",
    "            return signals\n",
    "    \n",
    "        # min/max parameter values\n",
    "        minT1 = 0.1\n",
    "        maxT1 = 7\n",
    "        # simulate parameter values\n",
    "        parameters = np.random.uniform(low=minT1, high=maxT1, size=(n_samples, 1))\n",
    "    \n",
    "        # generate data using an T1 inversion recovery model\n",
    "    \n",
    "        # make the super design\n",
    "        tr = 7  # repetition time\n",
    "        maxti = tr\n",
    "        minti = 0.1\n",
    "        acq_params_super = np.linspace(minti, maxti, Cbar)\n",
    "    \n",
    "        # generate the data\n",
    "        raw_signals = np.zeros((n_samples, Cbar), dtype=np.float32)\n",
    "        for i in range(0, n_samples):\n",
    "            raw_signals[i, :] = model(parameters[i], acq_params_super, tr)\n",
    "\n",
    "\n",
    "\n",
    "    # add noise to the data\n",
    "    def add_noise(data, scale=0.05):\n",
    "        data_real = data + np.random.normal(scale=scale, size=np.shape(data))\n",
    "        data_imag = np.random.normal(scale=scale, size=np.shape(data))\n",
    "        data_noisy = np.sqrt(data_real**2 + data_imag**2)\n",
    "    \n",
    "        return data_noisy\n",
    "    \n",
    "    \n",
    "    SNR = 20\n",
    "    signals = add_noise(raw_signals, 1 / SNR)\n",
    "\n",
    "    proj_name = model_name + \"_simulations_\" + \"n_train_\" + str(n_train) + \"_SNR_\" + str(SNR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_own_simulated_data:\n",
    "    #REPLACE WITH LOCATION OF THE SIMULATED DATA\n",
    "    basedir = '/Users/scmps8/repos/github.com/ED_MRI/ED_MRI/examples/t1inv_simulations_n_train_10000_SNR_20'\n",
    "\n",
    "    #Replace with project name\n",
    "    proj_name = 'TADRED_test'\n",
    "\n",
    "    #REPLACE WITH PATH TO SIMULATION GROUND TRUTH PARAMETERS\n",
    "    #saved array should be array n_samples by n_model_parameters     \n",
    "    simulation_gt_parameters_path = os.path.join(basedir,'parameters_gt_full.npy')\n",
    "    \n",
    "    #REPLACE WITH PATH TO SIMULATION GROUND TRUTH SIGNALS WITH \"SUPER-DESIGN\" ACQUISITION - HIGHLY OVERSAMPLING THE ACQUISITION PARAMETER SPACE\n",
    "    #array is n_samples by Cbar\n",
    "    simulation_gt_signals_path = os.path.join(basedir, 'signals_super_full.npy')\n",
    "    \n",
    "    #REPLACE WITH PATH TO SUPER-DESIGN ACQUISITION PARAMETERS\n",
    "    #acq_params_super - Cbar by n_acqusition_parameters length array containing the acquisition parameters of the superdesign\n",
    "\n",
    "    \n",
    "    #array is Cbar by n_acqusition_parameters, e.g. n_acqusition_parameters is 4 (gx, gy, gz, b) for HCP data\n",
    "    acq_params_super_signals_path = os.path.join(basedir, 'acq_params_super.npy')\n",
    "    \n",
    "    #load the files\n",
    "    parameters = np.load(simulation_gt_parameters_path)\n",
    "    signals = np.load(simulation_gt_signals_path)\n",
    "    acq_params_super = np.load(acq_params_super_signals_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## (3-A)\n",
    "# Create dummy, randomly generated (positive) data\n",
    "\n",
    "# C_bar = 220\n",
    "# M = 12  # Number of input measurements \\bar{C}, Target regressors\n",
    "# rand = np.random.lognormal  # Random genenerates positive\n",
    "# train_inp, train_tar = rand(size=(n_train, C_bar)), rand(size=(n_train, M))\n",
    "# val_inp, val_tar = rand(size=(n_val, C_bar)), rand(size=(n_val, M))\n",
    "# test_inp, test_tar = rand(size=(n_test, C_bar)), rand(size=(n_test, M))\n",
    "\n",
    "\n",
    "# #########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #convert signal and parameters to pytorch float32\n",
    "# import torch\n",
    "\n",
    "# signals = torch.tensor(signals, dtype=torch.float32)\n",
    "# parameters = torch.tensor(parameters, dtype=torch.float32)\n",
    "\n",
    "# signals = torch.tensor(signals, dtype=torch.float32)\n",
    "# parameters = torch.tensor(parameters, dtype=torch.float32)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## (4)\n",
    "# Load data into TADRED format\n",
    "\n",
    "# Data in TADRED format, \\bar{C} measurements, M target regresors\n",
    "data = dict(\n",
    "    train=signals[0:n_train, :],  # Shape n_train x \\bar{C}\n",
    "    train_tar=parameters[0:n_train, :],  # Shape n_train x M\n",
    "    val=signals[n_train : (n_train + n_val), :],  # Shape n_val x \\bar{C}\n",
    "    val_tar=parameters[n_train : (n_train + n_val), :],  # Shape n_val x M\n",
    "    test=signals[(n_train + n_val) : (n_train + n_val + n_test), :],  # Shape n_test x \\bar{C}\n",
    "    test_tar=parameters[(n_train + n_val) : (n_train + n_val + n_test), :],  # Shape n_test x M\n",
    ")\n",
    "\n",
    "for key, value in data.items():\n",
    "    data[key] = value.astype(np.float32)\n",
    "\n",
    "args = utils.load_base_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## 5\n",
    "\n",
    "#save data to disk so TADRED can load it\n",
    "proj_dir = Path(basedir, proj_name)\n",
    "proj_dir.mkdir(parents=True, exist_ok=True)\n",
    "np.save(Path(proj_dir, proj_name + \".npy\"), data)\n",
    "\n",
    "print(\"Saving data as\", Path(proj_dir, proj_name + \".npy\"))\n",
    "pass_data = None\n",
    "\n",
    "args.data_norm.data_fil = Path(proj_dir, proj_name + \".npy\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## (6)\n",
    "# Simplest version of TADRED, modifying the most important hyperparameters\n",
    "# Here the decreasing subset sizes are hard-coded so that the final optimized protocol is 1/16 the size of the superdesign.\n",
    "# Feel free to play around with the subset size reduction pattern, but halving the size of the subset sizes at each TADRED step seems to generally work well.\n",
    "\n",
    "\n",
    "# Decreasing feature subsets sizes for TADRED to consider\n",
    "args.tadred_train_eval.feature_set_sizes_Ci = [\n",
    "    Cbar,\n",
    "    Cbar // 2,\n",
    "    Cbar // 4,\n",
    "    Cbar // 8,\n",
    "    Cbar // 16,\n",
    "]\n",
    "\n",
    "# Feature subset sizess for TADRED evaluated on test data\n",
    "args.tadred_train_eval.feature_set_sizes_evaluated = [\n",
    "    Cbar // 2,\n",
    "    Cbar // 4,\n",
    "    Cbar // 8,\n",
    "    Cbar // 16,\n",
    "]\n",
    "\n",
    "# Scoring net Cbar -> num_units_score[0] -> num_units_score[1] ... -> Cbar units\n",
    "args.network.num_units_score = [1000, 1000]\n",
    "\n",
    "# Task net Cbar -> num_units_task[0] -> num_units_task[1] ... -> M units\n",
    "args.network.num_units_task = [1000, 1000]\n",
    "\n",
    "args.output.out_base = basedir  # \"/Users/paddyslator/python/ED_MRI/test1\" #\"/home/blumberg/Bureau/z_Automated_Measurement/Output/paddy\"\n",
    "args.output.proj_name = proj_name\n",
    "args.output.run_name = \"test\"\n",
    "args.other_options.save_output = True\n",
    "\n",
    "# tadred_args[\"total_epochs\"] = 1000\n",
    "\n",
    "TADRED_output = tadred_main.run(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also load the saved results here\n",
    "# TADRED_output = np.load(\n",
    "#     Path(\n",
    "#         proj_dir,\n",
    "#         \"results\",\n",
    "#         args.output.run_name + \"_all.npy\",\n",
    "#     ),\n",
    "#     allow_pickle=True,\n",
    "# ).item()\n",
    "\n",
    "\n",
    "# TADRED_output = np.load(\n",
    "#     Path(\n",
    "#         proj_dir,\n",
    "#         \"results\",\n",
    "#         args.output.run_name + \"_all.npy\",\n",
    "#     ),\n",
    "#     allow_pickle=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract some useful parameters fom the tadred output\n",
    "#final subset index\n",
    "Clast = TADRED_output[\"args\"][\"tadred_train_eval\"][\"feature_set_sizes_Ci\"][-1]\n",
    "\n",
    "#index of chosen acquisition parameters\n",
    "acq_params_tadred_index = TADRED_output[Clast][\"measurements\"]\n",
    "\n",
    "# chosen acquisition parameters\n",
    "acq_params_tadred = acq_params_super[acq_params_tadred_index]\n",
    "\n",
    "print('TADRED chosen acquisition parameters are: ' + str(acq_params_tadred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the signals at the super design and the tadred chosen for a single voxel\n",
    "#\n",
    "\n",
    "#if the number of acquisition parameters is bigger than one, need to choose which one to plot on the x axis\n",
    "if (acq_params_super.ndim > 1): \n",
    "    if (acq_params_super.shape[1] > 1):\n",
    "        acq_param_to_plot = 1\n",
    "        acq_params_super_to_plot = acq_params_super[:,acq_param_to_plot]\n",
    "        acq_params_tadred_to_plot = acq_params_tadred[:,acq_param_to_plot]\n",
    "        acq_params_tadred_index_to_plot = acq_params_tadred_index[:,acq_param_to_plot]\n",
    "else:\n",
    "    acq_params_super_to_plot = acq_params_super\n",
    "    acq_params_tadred_to_plot = acq_params_tadred\n",
    "    acq_params_tadred_index_to_plot = acq_params_tadred_index\n",
    "    \n",
    "voxel_to_plot = 0\n",
    "\n",
    "\n",
    "plt.plot(acq_params_super_to_plot, signals[voxel_to_plot,:], 'x')\n",
    "plt.plot(acq_params_tadred_to_plot, signals[voxel_to_plot,acq_params_tadred_index], 'o')\n",
    "\n",
    "plt.title('signals from voxel ' + str(voxel_to_plot))\n",
    "plt.legend(('Super design', 'TADRED chosen'))\n",
    "plt.ylabel('signal')\n",
    "plt.xlabel('acquisition parameter')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save TADRED acquisition parameters\n",
    "np.save(Path(proj_dir, \"acq_params_tadred.npy\"), acq_params_tadred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "615b1a4c774898c50e50cbbdb62428ce29922c4c76c6af0df5092a4f94b8ccac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
